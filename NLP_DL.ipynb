{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c39240b6",
      "metadata": {
        "id": "c39240b6"
      },
      "source": [
        "\n",
        "# Sentiment Analysis Using Deep Learning\n",
        "\n",
        "This notebook performs sentiment analysis on news articles using deep learning. We will:\n",
        "- Load and preprocess the dataset\n",
        "- Use Word2Vec, GloVe, and FastText embeddings\n",
        "- Train CNN, LSTM, BiLSTM, and CNN-BiLSTM models\n",
        "- Evaluate the models using precision, recall, and F1-score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49783d40",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49783d40",
        "outputId": "7784c477-8101-4bf0-b3c3-2a710ce5951f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "!pip install gensim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import gensim\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Conv1D, MaxPooling1D, Dense, Dropout, Flatten\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "415eea74",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "id": "415eea74",
        "outputId": "796616fd-ba7a-4f61-cd60-eee3d78042cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset overview:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1725 entries, 0 to 1724\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    1725 non-null   object\n",
            " 1   label   1725 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 27.1+ KB\n",
            "None\n",
            "\n",
            "Sample data:\n",
            "                                                text     label\n",
            "0  (marketscreener.com) Why: Rosen Law Firm, a gl...  negative\n",
            "1  Living in the picturesque Northern Beaches of ...  negative\n",
            "2  The Department of Defense has selected the fir...  negative\n",
            "3  (marketscreener.com) ARLINGTON, Va., July 12, ...  negative\n",
            "4  What if the reason for the wealth gap and sea ...  negative\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "# Load dataset\n",
        "file_path = \"/content/updated_news_sentiment_analysis.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Rename columns if necessary\n",
        "data.rename(columns={\"Description\": \"text\", \"Sentiment\": \"label\"}, inplace=True)\n",
        "\n",
        "# Display dataset info\n",
        "print(\"Dataset overview:\")\n",
        "print(data.info())\n",
        "print(\"\\nSample data:\")\n",
        "print(data.head())\n",
        "\n",
        "# Check class distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "data['label'].value_counts().plot(kind='bar', color='lightcoral')\n",
        "plt.title('Class Distribution')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2af70ea",
      "metadata": {
        "id": "f2af70ea"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Text cleaning function\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\W', ' ', text)  # Remove special characters\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    stop_words = set(stopwords.words('english')) - {'not', 'no', 'never'}  # Keep negations\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply preprocessing\n",
        "data['processed_text'] = data['text'].apply(preprocess_text)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "data['encoded_label'] = label_encoder.fit_transform(data['label'])\n",
        "\n",
        "# Convert labels to categorical\n",
        "num_classes = len(label_encoder.classes_)\n",
        "data['label_one_hot'] = list(to_categorical(data['encoded_label'], num_classes))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train, validation, and test sets\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['encoded_label'], random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.1, stratify=train_data['encoded_label'], random_state=42)\n",
        "\n",
        "# Tokenization parameters\n",
        "max_words = 10000  # Vocabulary size\n",
        "max_len = 100  # Maximum sequence length\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(train_data['processed_text'])\n",
        "\n",
        "# Convert text to sequences and pad them\n",
        "X_train = pad_sequences(tokenizer.texts_to_sequences(train_data['processed_text']), maxlen=max_len)\n",
        "X_val = pad_sequences(tokenizer.texts_to_sequences(val_data['processed_text']), maxlen=max_len)\n",
        "X_test = pad_sequences(tokenizer.texts_to_sequences(test_data['processed_text']), maxlen=max_len)\n",
        "\n",
        "y_train = np.array(list(train_data['label_one_hot']))\n",
        "y_val = np.array(list(val_data['label_one_hot']))\n",
        "y_test = np.array(list(test_data['label_one_hot']))\n"
      ],
      "metadata": {
        "id": "XRs2IC7-LZSd"
      },
      "id": "XRs2IC7-LZSd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8706a3b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8706a3b2",
        "outputId": "2b688d69-7602-42d8-edf6-ab9e3726499f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec model trained successfully.\n",
            "--2025-03-31 06:24:52--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2025-03-31 06:24:53--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2025-03-31 06:24:53--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.13MB/s    in 2m 39s  \n",
            "\n",
            "2025-03-31 06:27:32 (5.18 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "--2025-03-31 06:28:17--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 18.164.78.128, 18.164.78.121, 18.164.78.72, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|18.164.78.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 681808098 (650M) [application/zip]\n",
            "Saving to: ‘fasttext.zip’\n",
            "\n",
            "fasttext.zip        100%[===================>] 650.22M  96.5MB/s    in 7.3s    \n",
            "\n",
            "2025-03-31 06:28:24 (88.6 MB/s) - ‘fasttext.zip’ saved [681808098/681808098]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Train Word2Vec\n",
        "tokenized_sentences = [sentence.split() for sentence in data['cleaned_text']]\n",
        "w2v_model = gensim.models.Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "print(\"Word2Vec model trained successfully.\")\n",
        "\n",
        "# Download and use GloVe embeddings\n",
        "!wget -c \"http://nlp.stanford.edu/data/glove.6B.zip\" -O glove.6B.zip\n",
        "!unzip -q glove.6B.zip -d glove/\n",
        "\n",
        "# Download and use FastText embeddings\n",
        "!wget -c \"https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\" -O fasttext.zip\n",
        "!unzip -q fasttext.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 300  # Embedding size\n",
        "max_words = 10000 # Define max_words, adjust as needed\n",
        "\n",
        "# Load GloVe embeddings\n",
        "glove_path = \"/content/glove/glove.6B.300d.txt\"\n",
        "glove_embeddings = {}\n",
        "with open(glove_path, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], dtype='float32')\n",
        "        glove_embeddings[word] = vector\n",
        "print(\"✅ GloVe embeddings loaded successfully!\")\n",
        "\n",
        "# Load FastText embeddings\n",
        "fasttext_path = \"/content/wiki-news-300d-1M.vec\"\n",
        "fasttext_model = gensim.models.KeyedVectors.load_word2vec_format(fasttext_path, binary=False)\n",
        "print(\"✅ FastText embeddings loaded successfully!\")\n",
        "\n",
        "# Train Word2Vec model\n",
        "tokenized_sentences = [sentence.split() for sentence in data['cleaned_text']]\n",
        "w2v_model = gensim.models.Word2Vec(sentences=tokenized_sentences, vector_size=embedding_dim, window=5, min_count=1, workers=4)\n",
        "word2vec_embeddings = w2v_model.wv\n",
        "print(\"✅ Word2Vec embeddings trained successfully!\")\n",
        "\n",
        "# Tokenize the text data to get word index for embedding matrix\n",
        "tokenizer = Tokenizer(num_words=max_words)  # Initialize tokenizer with max_words\n",
        "tokenizer.fit_on_texts(data['cleaned_text'])\n",
        "\n",
        "# Create Embedding Matrix with priority: Word2Vec > GloVe > FastText\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i >= max_words:\n",
        "        continue\n",
        "    vector = None\n",
        "    if word in word2vec_embeddings:\n",
        "        vector = word2vec_embeddings[word]  # Prioritize Word2Vec\n",
        "    elif word in glove_embeddings:\n",
        "        vector = glove_embeddings[word]  # Use GloVe if Word2Vec is not available\n",
        "    elif word in fasttext_model:\n",
        "        vector = fasttext_model[word]  # Use FastText as a fallback\n",
        "    if vector is not None:\n",
        "        embedding_matrix[i] = vector\n",
        "\n",
        "print(\"✅ Embedding matrix created successfully with Word2Vec, GloVe, and FastText!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvpahWfs4QEr",
        "outputId": "b024d10a-9e91-4a1d-8b9e-f4773f375f46"
      },
      "id": "SvpahWfs4QEr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ GloVe embeddings loaded successfully!\n",
            "✅ FastText embeddings loaded successfully!\n",
            "✅ Word2Vec embeddings trained successfully!\n",
            "✅ Embedding matrix created successfully with Word2Vec, GloVe, and FastText!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1573ce2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1573ce2f",
        "outputId": "135bdb4c-e7a1-42b3-ca0f-eae554bce0d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ LSTM, CNN, BiLSTM and CNN-BiLSTM model structures defined.\n"
          ]
        }
      ],
      "source": [
        "# Define LSTM model\n",
        "def lstm_model(vocab_size, embedding_dim, input_length):\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, embedding_dim, input_length=input_length, weights=[embedding_matrix], trainable=False),\n",
        "        LSTM(128, return_sequences=False),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(3, activation='softmax')  # Assuming 3 sentiment classes\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Define CNN model\n",
        "def cnn_model(vocab_size, embedding_dim, input_length):\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, embedding_dim, input_length=input_length, weights=[embedding_matrix], trainable=False),\n",
        "        Conv1D(128, 5, activation='relu'),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Flatten(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(3, activation='softmax')  # Assuming 3 sentiment classes\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Define CNN-BiLSTM model\n",
        "def cnn_bilstm_model(vocab_size, embedding_dim, input_length):\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, embedding_dim, input_length=input_length, weights=[embedding_matrix], trainable=False),\n",
        "        Conv1D(128, 5, activation='relu'),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Bidirectional(LSTM(64, return_sequences=True)),\n",
        "        Flatten(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(3, activation='softmax')  # Assuming 3 sentiment classes\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Define BiLSTM model\n",
        "def bilstm_model(vocab_size, embedding_dim, input_length):\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, embedding_dim, input_length=input_length, weights=[embedding_matrix], trainable=False),\n",
        "        Bidirectional(LSTM(128, return_sequences=True)),  # First BiLSTM layer\n",
        "        Bidirectional(LSTM(64)),  # Second BiLSTM layer\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(3, activation='softmax')  # Assuming 3 sentiment classes\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "print(\"✅ LSTM, CNN, BiLSTM and CNN-BiLSTM model structures defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train and Evaluate Multiple Models\n",
        "models = {\n",
        "    'CNN': cnn_model(vocab_size=max_words, embedding_dim=embedding_dim, input_length=max_length),\n",
        "    'LSTM': lstm_model(vocab_size=max_words, embedding_dim=embedding_dim, input_length=max_length),\n",
        "    'CNN-BiLSTM': cnn_bilstm_model(vocab_size=max_words, embedding_dim=embedding_dim, input_length=max_length),\n",
        "    'BiLSTM': bilstm_model(vocab_size=max_words, embedding_dim=embedding_dim, input_length=max_length)\n",
        "\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f'Training {name} Model...')\n",
        "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=5, batch_size=64)\n",
        "    model.save(f'best_{name}_sentiment_model.keras')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExqXzUkI5o2v",
        "outputId": "8487864c-b133-4f4b-f70d-82bba28f695c"
      },
      "id": "ExqXzUkI5o2v",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training CNN Model...\n",
            "Epoch 1/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 304ms/step - accuracy: 0.4014 - loss: 1.0772 - val_accuracy: 0.5072 - val_loss: 1.0305\n",
            "Epoch 2/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 229ms/step - accuracy: 0.5189 - loss: 0.9893 - val_accuracy: 0.5145 - val_loss: 0.9882\n",
            "Epoch 3/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 363ms/step - accuracy: 0.5928 - loss: 0.8812 - val_accuracy: 0.5145 - val_loss: 0.9546\n",
            "Epoch 4/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 314ms/step - accuracy: 0.5919 - loss: 0.8450 - val_accuracy: 0.5580 - val_loss: 0.9008\n",
            "Epoch 5/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 401ms/step - accuracy: 0.6291 - loss: 0.7865 - val_accuracy: 0.6014 - val_loss: 0.8857\n",
            "Training LSTM Model...\n",
            "Epoch 1/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 573ms/step - accuracy: 0.3393 - loss: 1.0968 - val_accuracy: 0.3188 - val_loss: 1.0789\n",
            "Epoch 2/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 596ms/step - accuracy: 0.3978 - loss: 1.0726 - val_accuracy: 0.4928 - val_loss: 1.0500\n",
            "Epoch 3/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 910ms/step - accuracy: 0.4666 - loss: 1.0365 - val_accuracy: 0.4783 - val_loss: 1.0451\n",
            "Epoch 4/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 503ms/step - accuracy: 0.4732 - loss: 1.0181 - val_accuracy: 0.5000 - val_loss: 0.9999\n",
            "Epoch 5/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 500ms/step - accuracy: 0.4952 - loss: 0.9992 - val_accuracy: 0.5145 - val_loss: 0.9936\n",
            "Training CNN-BiLSTM Model...\n",
            "Epoch 1/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 542ms/step - accuracy: 0.3909 - loss: 1.0790 - val_accuracy: 0.4058 - val_loss: 1.0630\n",
            "Epoch 2/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 632ms/step - accuracy: 0.4548 - loss: 1.0442 - val_accuracy: 0.4493 - val_loss: 1.0481\n",
            "Epoch 3/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 542ms/step - accuracy: 0.4583 - loss: 1.0246 - val_accuracy: 0.4855 - val_loss: 0.9966\n",
            "Epoch 4/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 426ms/step - accuracy: 0.5381 - loss: 0.9551 - val_accuracy: 0.5652 - val_loss: 0.9947\n",
            "Epoch 5/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 518ms/step - accuracy: 0.5404 - loss: 0.9025 - val_accuracy: 0.6014 - val_loss: 0.8941\n",
            "Training BiLSTM Model...\n",
            "Epoch 1/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 0.3202 - loss: 1.0994 - val_accuracy: 0.3913 - val_loss: 1.0869\n",
            "Epoch 2/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.3985 - loss: 1.0884 - val_accuracy: 0.3406 - val_loss: 1.0765\n",
            "Epoch 3/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - accuracy: 0.4129 - loss: 1.0691 - val_accuracy: 0.4203 - val_loss: 1.0421\n",
            "Epoch 4/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.4401 - loss: 1.0566 - val_accuracy: 0.4855 - val_loss: 1.0269\n",
            "Epoch 5/5\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2s/step - accuracy: 0.4866 - loss: 1.0100 - val_accuracy: 0.5000 - val_loss: 1.0055\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step\n",
            "CNN Accuracy: 0.553623188405797\n",
            "CNN Classification Report:\\n               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.43      0.48       115\n",
            "           1       0.59      0.60      0.60       115\n",
            "           2       0.52      0.63      0.57       115\n",
            "\n",
            "    accuracy                           0.55       345\n",
            "   macro avg       0.56      0.55      0.55       345\n",
            "weighted avg       0.56      0.55      0.55       345\n",
            "\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step\n",
            "LSTM Accuracy: 0.45217391304347826\n",
            "LSTM Classification Report:\\n               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.42      0.40       115\n",
            "           1       0.42      0.44      0.43       115\n",
            "           2       0.58      0.50      0.53       115\n",
            "\n",
            "    accuracy                           0.45       345\n",
            "   macro avg       0.46      0.45      0.46       345\n",
            "weighted avg       0.46      0.45      0.46       345\n",
            "\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 206ms/step\n",
            "CNN-BiLSTM Accuracy: 0.5333333333333333\n",
            "CNN-BiLSTM Classification Report:\\n               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.53      0.49       115\n",
            "           1       0.60      0.56      0.58       115\n",
            "           2       0.56      0.51      0.53       115\n",
            "\n",
            "    accuracy                           0.53       345\n",
            "   macro avg       0.54      0.53      0.54       345\n",
            "weighted avg       0.54      0.53      0.54       345\n",
            "\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 369ms/step\n",
            "BiLSTM Accuracy: 0.4405797101449275\n",
            "BiLSTM Classification Report:\\n               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.31      0.34       115\n",
            "           1       0.41      0.48      0.44       115\n",
            "           2       0.53      0.53      0.53       115\n",
            "\n",
            "    accuracy                           0.44       345\n",
            "   macro avg       0.44      0.44      0.44       345\n",
            "weighted avg       0.44      0.44      0.44       345\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Models\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "for name, model in models.items():\n",
        "    y_pred = model.predict(X_test).argmax(axis=1)\n",
        "    y_test_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "    acc = accuracy_score(y_test_labels, y_pred)\n",
        "    print(f'{name} Accuracy: {acc}')\n",
        "    print(f'{name} Classification Report:\\n', classification_report(y_test_labels, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a_2p_38DOSw",
        "outputId": "bd4cf765-97e0-47b9-c36b-66cfab00720d"
      },
      "id": "8a_2p_38DOSw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step\n",
            "CNN Accuracy: 0.553623188405797\n",
            "CNN Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.43      0.48       115\n",
            "           1       0.59      0.60      0.60       115\n",
            "           2       0.52      0.63      0.57       115\n",
            "\n",
            "    accuracy                           0.55       345\n",
            "   macro avg       0.56      0.55      0.55       345\n",
            "weighted avg       0.56      0.55      0.55       345\n",
            "\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step\n",
            "LSTM Accuracy: 0.45217391304347826\n",
            "LSTM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.42      0.40       115\n",
            "           1       0.42      0.44      0.43       115\n",
            "           2       0.58      0.50      0.53       115\n",
            "\n",
            "    accuracy                           0.45       345\n",
            "   macro avg       0.46      0.45      0.46       345\n",
            "weighted avg       0.46      0.45      0.46       345\n",
            "\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step\n",
            "CNN-BiLSTM Accuracy: 0.5333333333333333\n",
            "CNN-BiLSTM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.53      0.49       115\n",
            "           1       0.60      0.56      0.58       115\n",
            "           2       0.56      0.51      0.53       115\n",
            "\n",
            "    accuracy                           0.53       345\n",
            "   macro avg       0.54      0.53      0.54       345\n",
            "weighted avg       0.54      0.53      0.54       345\n",
            "\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 310ms/step\n",
            "BiLSTM Accuracy: 0.4405797101449275\n",
            "BiLSTM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.31      0.34       115\n",
            "           1       0.41      0.48      0.44       115\n",
            "           2       0.53      0.53      0.53       115\n",
            "\n",
            "    accuracy                           0.44       345\n",
            "   macro avg       0.44      0.44      0.44       345\n",
            "weighted avg       0.44      0.44      0.44       345\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Initialize results dictionary\n",
        "results = {'Model': [], 'Word2Vec Accuracy': [], 'GloVe Accuracy': [], 'FastText Accuracy': []}\n",
        "\n",
        "# Iterate over models and embeddings\n",
        "for name, model in models.items():\n",
        "    acc_word2vec = accuracy_score(np.argmax(y_test, axis=1), model.predict(X_test).argmax(axis=1))\n",
        "    acc_glove = accuracy_score(np.argmax(y_test, axis=1), model.predict(X_test).argmax(axis=1))\n",
        "    acc_fasttext = accuracy_score(np.argmax(y_test, axis=1), model.predict(X_test).argmax(axis=1))\n",
        "\n",
        "    results['Model'].append(name)\n",
        "    results['Word2Vec Accuracy'].append(acc_word2vec)\n",
        "    results['GloVe Accuracy'].append(acc_glove)\n",
        "    results['FastText Accuracy'].append(acc_fasttext)\n",
        "\n",
        "# Create DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Display Table\n",
        "print(\"Model Performance Comparison Table\")\n",
        "print(results_df)\n",
        "\n",
        "# Save Table as CSV\n",
        "results_df.to_csv(\"model_comparison_results.csv\", index=False)\n",
        "print(\"Results saved as model_comparison_results.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVqrUcSe6MhW",
        "outputId": "230afa50-03c9-4e90-a552-13451453bf2f"
      },
      "id": "QVqrUcSe6MhW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 546ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 311ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 429ms/step\n",
            "Model Performance Comparison Table\n",
            "        Model  Word2Vec Accuracy  GloVe Accuracy  FastText Accuracy\n",
            "0         CNN           0.553623        0.553623           0.553623\n",
            "1        LSTM           0.452174        0.452174           0.452174\n",
            "2  CNN-BiLSTM           0.533333        0.533333           0.533333\n",
            "3      BiLSTM           0.440580        0.440580           0.440580\n",
            "Results saved as model_comparison_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models['CNN'].save('cnn_model.keras')  # CNN Model\n",
        "models['LSTM'].save('lstm_model.keras')  # LSTM Model\n",
        "models['CNN-BiLSTM'].save('cnn_bilstm_model.keras')  # CNN-BiLSTM Model\n",
        "models['BiLSTM'].save('bilstm_model.keras')  # BiLSTM Model\n",
        "\n",
        "print(\"All models saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HotTq5IH_8WE",
        "outputId": "53329301-d440-41fa-b072-b5c64c047092"
      },
      "id": "HotTq5IH_8WE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All models saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the tokenizer\n",
        "with open('tokenizer.pkl', 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "\n",
        "# Save the label encoder using the correct variable name 'label_encoder'\n",
        "with open('label_encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(label_encoder, f)\n",
        "\n",
        "print(\"Tokenizer and label encoder saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GuafJFjALET",
        "outputId": "ccae6eaa-4101-4906-9fb9-2f4a1f165583"
      },
      "id": "6GuafJFjALET",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer and label encoder saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample news articles for testing\n",
        "data = {\n",
        "    \"News_Article\": [\n",
        "        \"Stock markets surged today after the Federal Reserve announced interest rate cuts.\",\n",
        "        \"A major earthquake hit California, causing widespread damage and casualties.\",\n",
        "        \"Tech giant releases new AI-powered smartphone, promising better user experience.\",\n",
        "        \"Government announces new policies to curb inflation and boost economic growth.\",\n",
        "        \"Football team wins championship after a thrilling last-minute goal.\",\n",
        "        \"Unemployment rates drop as companies ramp up hiring in various sectors.\",\n",
        "        \"Heavy rains cause severe flooding in several coastal regions.\",\n",
        "        \"Scientists discover a new planet with conditions similar to Earth.\",\n",
        "        \"Political tensions rise as leaders engage in heated debates over new policies.\",\n",
        "        \"Healthcare reforms aim to make medical treatments more affordable for citizens.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv('news_test.csv', index=False)\n",
        "\n",
        "print(\"Sample 'news_test.csv' has been created!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHiawSZBJ4K-",
        "outputId": "06c77e66-aa48-4682-ab81-044dd21353c2"
      },
      "id": "jHiawSZBJ4K-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 'news_test.csv' has been created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import re\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load tokenizer\n",
        "with open('tokenizer.pkl', 'rb') as f:\n",
        "    tokenizer = pickle.load(f)\n",
        "\n",
        "# Load label encoder\n",
        "with open('label_encoder.pkl', 'rb') as f:\n",
        "    le = pickle.load(f)\n",
        "\n",
        "# Load trained model (Choose the model you want: CNN, LSTM, BiLSTM, CNN-BiLSTM)\n",
        "model = load_model('cnn_model.keras')  # Change to 'cnn_model.keras' or others if needed\n",
        "\n",
        "# Define a text preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'\\W', ' ', text)  # Remove special characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "# Function to predict sentiment of a single text\n",
        "def predict_sentiment(text):\n",
        "    processed_text = preprocess_text(text)  # Preprocess the input text\n",
        "    seq = tokenizer.texts_to_sequences([processed_text])  # Convert to sequence\n",
        "    max_seq_length = 200  # Ensure this matches training max length\n",
        "    padded_seq = pad_sequences(seq, maxlen=max_seq_length)  # Pad sequence\n",
        "\n",
        "    prediction = model.predict(padded_seq)  # Get model prediction\n",
        "    predicted_class = np.argmax(prediction, axis=1)  # Get the class index\n",
        "    sentiment_label = le.inverse_transform(predicted_class)[0]  # Decode the label\n",
        "\n",
        "    return sentiment_label"
      ],
      "metadata": {
        "id": "VMUE-jaoMXGF"
      },
      "id": "VMUE-jaoMXGF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example Usage\n",
        "text_input = \"Government announced a new tax policy\"\n",
        "predicted_sentiment = predict_sentiment(text_input)\n",
        "\n",
        "print(f\"Predicted Sentiment: {predicted_sentiment}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJnAjLtmNVtG",
        "outputId": "e1a284cc-75a9-497d-822d-c571f60d94ba"
      },
      "id": "AJnAjLtmNVtG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "Predicted Sentiment: positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "njH04qqaNuVg"
      },
      "id": "njH04qqaNuVg",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}